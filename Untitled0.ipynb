{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlUk2Ixjb4sidq/+QffpFx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhavanaSrinivasegowda/HW_for_AI_ML/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu4s3D4DVaFt",
        "outputId": "3f0ff8fb-3014-47fc-f3d3-374e076b1b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 30 21:25:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNiYr0XMVtVK",
        "outputId": "6ff951d0-5ce7-4584-c0fa-5e724fd0858e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile saxpy.cu\n",
        "#include <stdio.h>\n",
        "#include <math.h> // for fabsf\n",
        "\n",
        "__global__\n",
        "void saxpy(int n, float a, float *x, float *y)\n",
        "{\n",
        "  int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  if (i < n) y[i] = a*x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "  float *x, *y, *d_x, *d_y;\n",
        "  x = (float*)malloc(N*sizeof(float));\n",
        "  y = (float*)malloc(N*sizeof(float));\n",
        "\n",
        "  cudaMalloc(&d_x, N*sizeof(float));\n",
        "  cudaMalloc(&d_y, N*sizeof(float));\n",
        "\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        "\n",
        "  cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Perform SAXPY on 1M elements\n",
        "  saxpy<<<(N+255)/256, 256>>>(N, 2.0f, d_x, d_y);\n",
        "\n",
        "  cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmaxf(maxError, fabsf(y[i]-4.0f));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "\n",
        "  cudaFree(d_x);\n",
        "  cudaFree(d_y);\n",
        "  free(x);\n",
        "  free(y);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfpLQ0rSVwR2",
        "outputId": "cd495275-b4d5-4b72-d407-c955b0254adf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing saxpy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 saxpy.cu -o saxpy"
      ],
      "metadata": {
        "id": "xY131ZN8WDOS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./saxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l82YxFXyWQYf",
        "outputId": "16db07f9-0648-430a-fb38-ac7666f70a7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile saxpy_debug.cu\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__\n",
        "void saxpy(int n, float a, float *x, float *y)\n",
        "{\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < n) y[i] = a * x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  for (int exp = 15; exp <= 25; exp++) {\n",
        "    int N = 1 << exp;\n",
        "    float *x, *y, *d_x, *d_y;\n",
        "\n",
        "    x = (float*)malloc(N * sizeof(float));\n",
        "    y = (float*)malloc(N * sizeof(float));\n",
        "\n",
        "    if (cudaMalloc(&d_x, N * sizeof(float)) != cudaSuccess ||\n",
        "        cudaMalloc(&d_y, N * sizeof(float)) != cudaSuccess) {\n",
        "      printf(\"CUDA malloc failed for N = %d\\n\", N);\n",
        "      free(x); free(y);\n",
        "      continue;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "      x[i] = 1.0f;\n",
        "      y[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_y, y, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    saxpy<<<(N + 255) / 256, 256>>>(N, 2.0f, d_x, d_y);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    // ✅ Check for kernel launch errors\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "      printf(\"CUDA kernel launch failed: %s\\n\", cudaGetErrorString(err));\n",
        "      cudaFree(d_x); cudaFree(d_y); free(x); free(y);\n",
        "      continue;\n",
        "    }\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(y, d_y, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < N; i++)\n",
        "      maxError = fmaxf(maxError, fabsf(y[i] - 4.0f));\n",
        "\n",
        "    printf(\"N = 2^%d (%d): Max error = %f, Time = %.3f ms\\n\", exp, N, maxError, milliseconds);\n",
        "\n",
        "    // ✅ Print a few y values to confirm correctness\n",
        "    printf(\"Sample values: y[0] = %.1f, y[1] = %.1f, y[N-1] = %.1f\\n\\n\", y[0], y[1], y[N-1]);\n",
        "\n",
        "    cudaFree(d_x);\n",
        "    cudaFree(d_y);\n",
        "    free(x);\n",
        "    free(y);\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPF5b1IkWSm_",
        "outputId": "10b76c7a-70fc-449e-f40b-29ddd7b7ae86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing saxpy_debug.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 saxpy_debug.cu -o saxpy_debug"
      ],
      "metadata": {
        "id": "VPIb93VqWndw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./saxpy_debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_PWha0jWuPA",
        "outputId": "442f9c71-c747-4c66-a80b-88f1bc10df66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 2^15 (32768): Max error = 0.000000, Time = 0.099 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^16 (65536): Max error = 0.000000, Time = 0.016 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^17 (131072): Max error = 0.000000, Time = 0.013 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^18 (262144): Max error = 0.000000, Time = 0.017 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^19 (524288): Max error = 0.000000, Time = 0.022 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^20 (1048576): Max error = 0.000000, Time = 0.053 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^21 (2097152): Max error = 0.000000, Time = 0.102 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^22 (4194304): Max error = 0.000000, Time = 0.192 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^23 (8388608): Max error = 0.000000, Time = 0.386 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^24 (16777216): Max error = 0.000000, Time = 0.771 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^25 (33554432): Max error = 0.000000, Time = 1.526 ms\n",
            "Sample values: y[0] = 4.0, y[1] = 4.0, y[N-1] = 4.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile saxpy_fancy.cu\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__\n",
        "void saxpy(int n, float a, float *x, float *y) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < n) y[i] = a * x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  for (int exp = 15; exp <= 25; exp++) {\n",
        "    int N = 1 << exp;\n",
        "    float *x, *y, *d_x, *d_y;\n",
        "\n",
        "    // Start total timer\n",
        "    cudaEvent_t total_start, total_stop;\n",
        "    cudaEventCreate(&total_start);\n",
        "    cudaEventCreate(&total_stop);\n",
        "    cudaEventRecord(total_start);\n",
        "\n",
        "    x = (float*)malloc(N * sizeof(float));\n",
        "    y = (float*)malloc(N * sizeof(float));\n",
        "\n",
        "    if (cudaMalloc(&d_x, N * sizeof(float)) != cudaSuccess ||\n",
        "        cudaMalloc(&d_y, N * sizeof(float)) != cudaSuccess) {\n",
        "      printf(\"CUDA malloc failed for N = %d\\n\", N);\n",
        "      free(x); free(y);\n",
        "      continue;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "      x[i] = 1.0f;\n",
        "      y[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_y, y, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Start kernel-only timer\n",
        "    cudaEvent_t kernel_start, kernel_stop;\n",
        "    cudaEventCreate(&kernel_start);\n",
        "    cudaEventCreate(&kernel_stop);\n",
        "    cudaEventRecord(kernel_start);\n",
        "\n",
        "    saxpy<<<(N + 255) / 256, 256>>>(N, 2.0f, d_x, d_y);\n",
        "\n",
        "    cudaEventRecord(kernel_stop);\n",
        "    cudaEventSynchronize(kernel_stop);\n",
        "\n",
        "    cudaMemcpy(y, d_y, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // End total timer\n",
        "    cudaEventRecord(total_stop);\n",
        "    cudaEventSynchronize(total_stop);\n",
        "\n",
        "    // Calculate times\n",
        "    float kernel_time = 0, total_time = 0;\n",
        "    cudaEventElapsedTime(&kernel_time, kernel_start, kernel_stop);\n",
        "    cudaEventElapsedTime(&total_time, total_start, total_stop);\n",
        "\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < N; i++)\n",
        "      maxError = fmaxf(maxError, fabsf(y[i] - 4.0f));\n",
        "\n",
        "    printf(\"N = 2^%d (%d): Max error = %.6f\\n\", exp, N, maxError);\n",
        "    printf(\" → Kernel-only time: %.3f ms\\n\", kernel_time);\n",
        "    printf(\" → Total execution time: %.3f ms\\n\", total_time);\n",
        "    printf(\" → Sample y[0] = %.1f, y[N-1] = %.1f\\n\\n\", y[0], y[N - 1]);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_x); cudaFree(d_y); free(x); free(y);\n",
        "    cudaEventDestroy(total_start); cudaEventDestroy(total_stop);\n",
        "    cudaEventDestroy(kernel_start); cudaEventDestroy(kernel_stop);\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3krx6SvOXhiJ",
        "outputId": "10209fc6-dbc2-47b2-8342-cc134e938df8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing saxpy_fancy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 saxpy_fancy.cu -o saxpy_fancy"
      ],
      "metadata": {
        "id": "B6_qtEaSXp_g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./saxpy_fancy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2tPQHT3XxPz",
        "outputId": "b54113e3-1284-4052-e6f9-6b19b3312504"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 2^15 (32768): Max error = 0.000000\n",
            " → Kernel-only time: 0.133 ms\n",
            " → Total execution time: 0.641 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^16 (65536): Max error = 0.000000\n",
            " → Kernel-only time: 0.015 ms\n",
            " → Total execution time: 0.825 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^17 (131072): Max error = 0.000000\n",
            " → Kernel-only time: 0.013 ms\n",
            " → Total execution time: 1.201 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^18 (262144): Max error = 0.000000\n",
            " → Kernel-only time: 0.019 ms\n",
            " → Total execution time: 2.192 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^19 (524288): Max error = 0.000000\n",
            " → Kernel-only time: 0.023 ms\n",
            " → Total execution time: 4.267 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^20 (1048576): Max error = 0.000000\n",
            " → Kernel-only time: 0.052 ms\n",
            " → Total execution time: 9.197 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^21 (2097152): Max error = 0.000000\n",
            " → Kernel-only time: 0.104 ms\n",
            " → Total execution time: 18.682 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^22 (4194304): Max error = 0.000000\n",
            " → Kernel-only time: 0.191 ms\n",
            " → Total execution time: 39.646 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^23 (8388608): Max error = 0.000000\n",
            " → Kernel-only time: 0.387 ms\n",
            " → Total execution time: 77.752 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^24 (16777216): Max error = 0.000000\n",
            " → Kernel-only time: 0.769 ms\n",
            " → Total execution time: 154.398 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n",
            "N = 2^25 (33554432): Max error = 0.000000\n",
            " → Kernel-only time: 1.527 ms\n",
            " → Total execution time: 313.784 ms\n",
            " → Sample y[0] = 4.0, y[N-1] = 4.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fibonacci.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void fibonacci_kernel(unsigned long long *fib, int N) {\n",
        "  // Only one thread computes the whole sequence\n",
        "  if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "    fib[0] = 0;\n",
        "    if (N > 1) fib[1] = 1;\n",
        "\n",
        "    for (int i = 2; i < N; ++i) {\n",
        "      fib[i] = fib[i - 1] + fib[i - 2];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 93; // Upper limit for unsigned long long\n",
        "  unsigned long long *fib, *d_fib;\n",
        "\n",
        "  // Allocate memory on host and device\n",
        "  fib = (unsigned long long*)malloc(N * sizeof(unsigned long long));\n",
        "  cudaMalloc(&d_fib, N * sizeof(unsigned long long));\n",
        "\n",
        "  // Launch 1 thread to do the entire sequence computation\n",
        "  fibonacci_kernel<<<1, 1>>>(d_fib, N);\n",
        "\n",
        "  // Copy back result\n",
        "  cudaMemcpy(fib, d_fib, N * sizeof(unsigned long long), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Print result\n",
        "  for (int i = 0; i < N; i++)\n",
        "    printf(\"F[%d] = %llu\\n\", i, fib[i]);\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(d_fib);\n",
        "  free(fib);\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaa2qj26a-fn",
        "outputId": "1c2b8933-19dd-45c2-a1e0-6fd7a6dd1093"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fibonacci.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 fibonacci.cu -o fibo"
      ],
      "metadata": {
        "id": "05jzAB-tbJq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./fibo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCiT1VbocLII",
        "outputId": "2683abd1-8363-4ce2-df68-c1e792ae8d35"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F[0] = 0\n",
            "F[1] = 1\n",
            "F[2] = 1\n",
            "F[3] = 2\n",
            "F[4] = 3\n",
            "F[5] = 5\n",
            "F[6] = 8\n",
            "F[7] = 13\n",
            "F[8] = 21\n",
            "F[9] = 34\n",
            "F[10] = 55\n",
            "F[11] = 89\n",
            "F[12] = 144\n",
            "F[13] = 233\n",
            "F[14] = 377\n",
            "F[15] = 610\n",
            "F[16] = 987\n",
            "F[17] = 1597\n",
            "F[18] = 2584\n",
            "F[19] = 4181\n",
            "F[20] = 6765\n",
            "F[21] = 10946\n",
            "F[22] = 17711\n",
            "F[23] = 28657\n",
            "F[24] = 46368\n",
            "F[25] = 75025\n",
            "F[26] = 121393\n",
            "F[27] = 196418\n",
            "F[28] = 317811\n",
            "F[29] = 514229\n",
            "F[30] = 832040\n",
            "F[31] = 1346269\n",
            "F[32] = 2178309\n",
            "F[33] = 3524578\n",
            "F[34] = 5702887\n",
            "F[35] = 9227465\n",
            "F[36] = 14930352\n",
            "F[37] = 24157817\n",
            "F[38] = 39088169\n",
            "F[39] = 63245986\n",
            "F[40] = 102334155\n",
            "F[41] = 165580141\n",
            "F[42] = 267914296\n",
            "F[43] = 433494437\n",
            "F[44] = 701408733\n",
            "F[45] = 1134903170\n",
            "F[46] = 1836311903\n",
            "F[47] = 2971215073\n",
            "F[48] = 4807526976\n",
            "F[49] = 7778742049\n",
            "F[50] = 12586269025\n",
            "F[51] = 20365011074\n",
            "F[52] = 32951280099\n",
            "F[53] = 53316291173\n",
            "F[54] = 86267571272\n",
            "F[55] = 139583862445\n",
            "F[56] = 225851433717\n",
            "F[57] = 365435296162\n",
            "F[58] = 591286729879\n",
            "F[59] = 956722026041\n",
            "F[60] = 1548008755920\n",
            "F[61] = 2504730781961\n",
            "F[62] = 4052739537881\n",
            "F[63] = 6557470319842\n",
            "F[64] = 10610209857723\n",
            "F[65] = 17167680177565\n",
            "F[66] = 27777890035288\n",
            "F[67] = 44945570212853\n",
            "F[68] = 72723460248141\n",
            "F[69] = 117669030460994\n",
            "F[70] = 190392490709135\n",
            "F[71] = 308061521170129\n",
            "F[72] = 498454011879264\n",
            "F[73] = 806515533049393\n",
            "F[74] = 1304969544928657\n",
            "F[75] = 2111485077978050\n",
            "F[76] = 3416454622906707\n",
            "F[77] = 5527939700884757\n",
            "F[78] = 8944394323791464\n",
            "F[79] = 14472334024676221\n",
            "F[80] = 23416728348467685\n",
            "F[81] = 37889062373143906\n",
            "F[82] = 61305790721611591\n",
            "F[83] = 99194853094755497\n",
            "F[84] = 160500643816367088\n",
            "F[85] = 259695496911122585\n",
            "F[86] = 420196140727489673\n",
            "F[87] = 679891637638612258\n",
            "F[88] = 1100087778366101931\n",
            "F[89] = 1779979416004714189\n",
            "F[90] = 2880067194370816120\n",
            "F[91] = 4660046610375530309\n",
            "F[92] = 7540113804746346429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_NN.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cmath>\n",
        "\n",
        "#define INPUT_SIZE 4\n",
        "#define HIDDEN_SIZE 5\n",
        "#define OUTPUT_SIZE 1\n",
        "\n",
        "__device__ float relu(float x) {\n",
        "    return x > 0 ? x : 0;\n",
        "}\n",
        "\n",
        "__device__ float sigmoid(float x) {\n",
        "    return 1.0f / (1.0f + expf(-x));\n",
        "}\n",
        "\n",
        "__global__ void compute_hidden(float *input, float *weights1, float *bias1, float *hidden_out) {\n",
        "    int i = threadIdx.x;\n",
        "    if (i < HIDDEN_SIZE) {\n",
        "        float sum = 0;\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            sum += input[j] * weights1[i * INPUT_SIZE + j];\n",
        "        }\n",
        "        hidden_out[i] = relu(sum + bias1[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void compute_output(float *hidden_out, float *weights2, float *bias2, float *output) {\n",
        "    float sum = 0;\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        sum += hidden_out[i] * weights2[i];\n",
        "    }\n",
        "    *output = sigmoid(sum + *bias2);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float h_input[INPUT_SIZE] = {1.0, 2.0, 3.0, 4.0};\n",
        "    float h_weights1[HIDDEN_SIZE * INPUT_SIZE] = {\n",
        "        0.2, 0.4, 0.1, 0.3,\n",
        "        0.5, 0.6, 0.2, 0.1,\n",
        "        0.3, 0.8, 0.5, 0.2,\n",
        "        0.9, 0.4, 0.3, 0.7,\n",
        "        0.6, 0.5, 0.2, 0.8\n",
        "    };\n",
        "    float h_bias1[HIDDEN_SIZE] = {0.1, 0.2, 0.3, 0.1, 0.0};\n",
        "    float h_weights2[HIDDEN_SIZE] = {0.3, 0.7, 0.5, 0.6, 0.4};\n",
        "    float h_bias2 = 0.1;\n",
        "    float h_output = 0;\n",
        "\n",
        "    float *d_input, *d_weights1, *d_bias1, *d_hidden_out;\n",
        "    float *d_weights2, *d_bias2, *d_output;\n",
        "\n",
        "    cudaMalloc((void**)&d_input, INPUT_SIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&d_weights1, HIDDEN_SIZE * INPUT_SIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&d_bias1, HIDDEN_SIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&d_hidden_out, HIDDEN_SIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&d_weights2, HIDDEN_SIZE * sizeof(float));\n",
        "    cudaMalloc((void**)&d_bias2, sizeof(float));\n",
        "    cudaMalloc((void**)&d_output, sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, INPUT_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_weights1, h_weights1, HIDDEN_SIZE * INPUT_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bias1, h_bias1, HIDDEN_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_weights2, h_weights2, HIDDEN_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bias2, &h_bias2, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    compute_hidden<<<1, HIDDEN_SIZE>>>(d_input, d_weights1, d_bias1, d_hidden_out);\n",
        "    compute_output<<<1, 1>>>(d_hidden_out, d_weights2, d_bias2, d_output);\n",
        "\n",
        "    cudaMemcpy(&h_output, d_output, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Output: \" << h_output << std::endl;\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_weights1);\n",
        "    cudaFree(d_bias1);\n",
        "    cudaFree(d_hidden_out);\n",
        "    cudaFree(d_weights2);\n",
        "    cudaFree(d_bias2);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh-N1Wp0kWVS",
        "outputId": "9dfac2a6-0b58-4179-d937-74c794e15c6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_NN.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 cuda_NN.cu -o NN"
      ],
      "metadata": {
        "id": "l8ktEA2wmCSU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./NN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53G81tG0mHQC",
        "outputId": "feaeb3be-8d4d-4d85-8556-d52155b8d38c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: 0.999976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pytorch_NN.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleFFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleFFNN().to(device)\n",
        "\n",
        "input_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0]], device=device)\n",
        "output = model(input_tensor)\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "print(\"Output:\", output.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiSk5cjkpEuN",
        "outputId": "3311c83e-103b-4b15-969f-0538fcd59aae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pytorch_NN.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUQisjAupO0J",
        "outputId": "815d992a-5da0-4af3-e62a-d6f6bc84b7ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define a simple feedforward neural network\n",
        "class SimpleFFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 5)  # Input layer (4) → Hidden layer (5)\n",
        "        self.fc2 = nn.Linear(5, 1)  # Hidden layer (5) → Output layer (1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))         # ReLU activation for hidden layer\n",
        "        x = torch.sigmoid(self.fc2(x))  # Sigmoid for output\n",
        "        return x\n",
        "\n",
        "# Choose device: GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize model and move to device\n",
        "model = SimpleFFNN().to(device)\n",
        "\n",
        "# Dummy input tensor\n",
        "input_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0]], device=device)\n",
        "\n",
        "# Forward pass\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Print results\n",
        "print(\"Using device:\", device)\n",
        "print(\"Model output:\", output.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yQWjxvap57g",
        "outputId": "5c3c4abb-2966-45ad-8090-c790a614c4e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model output: 0.42889878153800964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_NN_timing.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cmath>\n",
        "#include <chrono>\n",
        "\n",
        "#define INPUT_SIZE 4\n",
        "#define HIDDEN_SIZE 5\n",
        "#define OUTPUT_SIZE 1\n",
        "#define ITERATIONS 10000\n",
        "\n",
        "__device__ float relu(float x) {\n",
        "    return x > 0 ? x : 0;\n",
        "}\n",
        "\n",
        "__device__ float sigmoid(float x) {\n",
        "    return 1.0f / (1.0f + expf(-x));\n",
        "}\n",
        "\n",
        "__global__ void compute_hidden(float *input, float *weights1, float *bias1, float *hidden_out) {\n",
        "    int i = threadIdx.x;\n",
        "    if (i < HIDDEN_SIZE) {\n",
        "        float sum = 0;\n",
        "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
        "            sum += input[j] * weights1[i * INPUT_SIZE + j];\n",
        "        }\n",
        "        hidden_out[i] = relu(sum + bias1[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void compute_output(float *hidden_out, float *weights2, float *bias2, float *output) {\n",
        "    float sum = 0;\n",
        "    for (int i = 0; i < HIDDEN_SIZE; i++) {\n",
        "        sum += hidden_out[i] * weights2[i];\n",
        "    }\n",
        "    *output = sigmoid(sum + *bias2);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float h_input[INPUT_SIZE] = {1.0, 2.0, 3.0, 4.0};\n",
        "    float h_weights1[HIDDEN_SIZE * INPUT_SIZE] = {\n",
        "        0.2, 0.4, 0.1, 0.3,\n",
        "        0.5, 0.6, 0.2, 0.1,\n",
        "        0.3, 0.8, 0.5, 0.2,\n",
        "        0.9, 0.4, 0.3, 0.7,\n",
        "        0.6, 0.5, 0.2, 0.8\n",
        "    };\n",
        "    float h_bias1[HIDDEN_SIZE] = {0.1, 0.2, 0.3, 0.1, 0.0};\n",
        "    float h_weights2[HIDDEN_SIZE] = {0.3, 0.7, 0.5, 0.6, 0.4};\n",
        "    float h_bias2 = 0.1;\n",
        "    float h_output = 0;\n",
        "\n",
        "    float *d_input, *d_weights1, *d_bias1, *d_hidden_out;\n",
        "    float *d_weights2, *d_bias2, *d_output;\n",
        "\n",
        "    cudaMalloc(&d_input, INPUT_SIZE * sizeof(float));\n",
        "    cudaMalloc(&d_weights1, HIDDEN_SIZE * INPUT_SIZE * sizeof(float));\n",
        "    cudaMalloc(&d_bias1, HIDDEN_SIZE * sizeof(float));\n",
        "    cudaMalloc(&d_hidden_out, HIDDEN_SIZE * sizeof(float));\n",
        "    cudaMalloc(&d_weights2, HIDDEN_SIZE * sizeof(float));\n",
        "    cudaMalloc(&d_bias2, sizeof(float));\n",
        "    cudaMalloc(&d_output, sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, INPUT_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_weights1, h_weights1, HIDDEN_SIZE * INPUT_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bias1, h_bias1, HIDDEN_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_weights2, h_weights2, HIDDEN_SIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bias2, &h_bias2, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Warmup\n",
        "    for (int i = 0; i < 100; ++i) {\n",
        "        compute_hidden<<<1, HIDDEN_SIZE>>>(d_input, d_weights1, d_bias1, d_hidden_out);\n",
        "        compute_output<<<1, 1>>>(d_hidden_out, d_weights2, d_bias2, d_output);\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Benchmarking\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    for (int i = 0; i < ITERATIONS; ++i) {\n",
        "        compute_hidden<<<1, HIDDEN_SIZE>>>(d_input, d_weights1, d_bias1, d_hidden_out);\n",
        "        compute_output<<<1, 1>>>(d_hidden_out, d_weights2, d_bias2, d_output);\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    std::chrono::duration<double, std::milli> elapsed = end - start;\n",
        "    std::cout << \"CUDA Avg Inference Time: \" << (elapsed.count() / ITERATIONS) << \" ms\" << std::endl;\n",
        "\n",
        "    cudaMemcpy(&h_output, d_output, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    std::cout << \"Final Output: \" << h_output << std::endl;\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_weights1);\n",
        "    cudaFree(d_bias1);\n",
        "    cudaFree(d_hidden_out);\n",
        "    cudaFree(d_weights2);\n",
        "    cudaFree(d_bias2);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBV_Aro8rweN",
        "outputId": "3a858278-750b-4a3d-96f4-03977a355974"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_NN_timing.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 cuda_NN_timing.cu -o NN_timing"
      ],
      "metadata": {
        "id": "R9_2ehGir-h2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./NN_timing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgJI4DYXsDlR",
        "outputId": "d8a3b27b-6c04-4a32-c9dd-083dbce74d4d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Avg Inference Time: 0.00681973 ms\n",
            "Final Output: 0.999976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pytorch_NN_timing.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "class SimpleFFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleFFNN().to(device)\n",
        "\n",
        "input_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0]], device=device)\n",
        "iterations = 10000\n",
        "\n",
        "# Warm-up\n",
        "for _ in range(100):\n",
        "    _ = model(input_tensor)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "# Benchmarking\n",
        "start = time.time()\n",
        "for _ in range(iterations):\n",
        "    output = model(input_tensor)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "end = time.time()\n",
        "\n",
        "avg_time = (end - start) * 1000 / iterations\n",
        "print(f\"PyTorch Avg Inference Time: {avg_time:.6f} ms\")\n",
        "print(\"Final Output:\", output.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfm91QcsKch",
        "outputId": "03208f3d-142b-45c7-f079-0aea8be579f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pytorch_NN_timing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "class SimpleFFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleFFNN().to(device)\n",
        "\n",
        "input_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0]], device=device)\n",
        "iterations = 10000\n",
        "\n",
        "# Warm-up\n",
        "for _ in range(100):\n",
        "    _ = model(input_tensor)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "# Benchmarking\n",
        "start = time.time()\n",
        "for _ in range(iterations):\n",
        "    output = model(input_tensor)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "end = time.time()\n",
        "\n",
        "avg_time = (end - start) * 1000 / iterations\n",
        "print(f\"PyTorch Avg Inference Time: {avg_time:.6f} ms\")\n",
        "print(\"Final Output:\", output.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZlBZtjWsUx1",
        "outputId": "1921fe70-8dc7-4c61-ee68-b4fecbd53143"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Avg Inference Time: 0.235297 ms\n",
            "Final Output: 0.2794197201728821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile NN_SIZES_compare.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define FFNN model builder\n",
        "def create_model(input_size, hidden_size, depth, output_size):\n",
        "    layers = [nn.Linear(input_size, hidden_size)]\n",
        "    for _ in range(depth - 1):\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "    layers.append(nn.ReLU())\n",
        "    layers.append(nn.Linear(hidden_size, output_size))\n",
        "    layers.append(nn.Sigmoid())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Benchmark function\n",
        "def benchmark_model(model, input_tensor, iterations=1000):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Warm-up\n",
        "    for _ in range(10):\n",
        "        _ = model(input_tensor)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    # Benchmarking\n",
        "    start = time.time()\n",
        "    for _ in range(iterations):\n",
        "        _ = model(input_tensor)\n",
        "        if device.type == 'cuda':\n",
        "            torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    return (end - start) * 1000 / iterations  # average ms\n",
        "\n",
        "# Config\n",
        "depths = [2, 4, 6, 8, 10]\n",
        "widths = [64, 128, 256, 512]\n",
        "input_size = 4\n",
        "output_size = 1\n",
        "batch_size = 1\n",
        "iterations = 1000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Benchmarking loop\n",
        "for width in widths:\n",
        "    avg_times = []\n",
        "    for depth in depths:\n",
        "        model = create_model(input_size, width, depth, output_size).to(device)\n",
        "        input_tensor = torch.rand(batch_size, input_size, device=device)\n",
        "        avg_time = benchmark_model(model, input_tensor, iterations)\n",
        "        avg_times.append(avg_time)\n",
        "    results[f'Width {width}'] = avg_times\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "for label, times in results.items():\n",
        "    plt.plot(depths, times, marker='o', label=label)\n",
        "\n",
        "plt.xlabel('Network Depth (# of Layers)')\n",
        "plt.ylabel('Avg Inference Time per Sample (ms)')\n",
        "plt.title('PyTorch FFNN Benchmark (Variable Depth & Width)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNahzlyFt4qe",
        "outputId": "158aea16-9a85-4c96-baf7-01cbadc86725"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing NN_SIZES_compare.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sorting_code.py\n",
        "import torch\n",
        "\n",
        "# Enable GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def bubble_sort_gpu(arr):\n",
        "    n = len(arr)\n",
        "    data = torch.tensor(arr, dtype=torch.float32, device=device)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(0, n - i - 1):\n",
        "            if data[j].item() > data[j+1].item():\n",
        "                temp = data[j].item()\n",
        "                data[j] = data[j+1].item()\n",
        "                data[j+1] = temp\n",
        "\n",
        "    return data.cpu().numpy()\n",
        "\n",
        "# Take user input\n",
        "user_input = input(\"Enter numbers separated by spaces: \")\n",
        "arr = list(map(float, user_input.strip().split()))\n",
        "\n",
        "# Run bubble sort\n",
        "sorted_arr = bubble_sort_gpu(arr)\n",
        "\n",
        "print(\"Sorted Array:\", sorted_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njmYQFjU2UzC",
        "outputId": "c668d2e2-6bd3-4883-e4cd-267e66f72007"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sorting_code.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sorting_compare.py\n",
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def bubble_sort_gpu(arr):\n",
        "    n = len(arr)\n",
        "    data = torch.tensor(arr, dtype=torch.float32, device=device)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(0, n - i - 1):\n",
        "            if data[j].item() > data[j+1].item():\n",
        "                temp = data[j].item()\n",
        "                data[j] = data[j+1].item()\n",
        "                data[j+1] = temp\n",
        "\n",
        "    return data.cpu().numpy()\n",
        "\n",
        "sizes = [10, 100, 500, 1000]\n",
        "times = []\n",
        "\n",
        "for size in sizes:\n",
        "    arr = np.random.rand(size) * 1000\n",
        "    start = time.time()\n",
        "    bubble_sort_gpu(arr)\n",
        "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
        "    end = time.time()\n",
        "    times.append((end - start) * 1000)\n",
        "\n",
        "plt.plot(sizes, times, marker='o')\n",
        "plt.title(\"Bubble Sort on GPU - Execution Time vs Input Size\")\n",
        "plt.xlabel(\"Array Size\")\n",
        "plt.ylabel(\"Execution Time (ms)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NBOgnsb3Sip",
        "outputId": "7eef736b-b0f8-41d2-d967-8bf06049f481"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sorting_compare.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sorting_test.py\n",
        "import unittest\n",
        "import torch\n",
        "\n",
        "# Bubble sort function (from your code)\n",
        "def bubble_sort_gpu(arr):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n = len(arr)\n",
        "    data = torch.tensor(arr, dtype=torch.float32, device=device)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(0, n - i - 1):\n",
        "            if data[j].item() > data[j + 1].item():\n",
        "                temp = data[j].item()\n",
        "                data[j] = data[j + 1].item()\n",
        "                data[j + 1] = temp\n",
        "\n",
        "    return data.cpu().numpy()\n",
        "\n",
        "# Unit test class\n",
        "class TestBubbleSortGPU(unittest.TestCase):\n",
        "\n",
        "    def test_sorted_array(self):\n",
        "        self.assertTrue(np.allclose(bubble_sort_gpu([1, 2, 3]), [1, 2, 3]))\n",
        "\n",
        "    def test_reverse_array(self):\n",
        "        self.assertTrue(np.allclose(bubble_sort_gpu([3, 2, 1]), [1, 2, 3]))\n",
        "\n",
        "    def test_unsorted_array(self):\n",
        "        self.assertTrue(np.allclose(bubble_sort_gpu([64, 34, 25, 12, 22, 11, 90]), sorted([64, 34, 25, 12, 22, 11, 90])))\n",
        "\n",
        "    def test_duplicates(self):\n",
        "        self.assertTrue(np.allclose(bubble_sort_gpu([5, 1, 2, 2, 3]), sorted([5, 1, 2, 2, 3])))\n",
        "\n",
        "    def test_empty_array(self):\n",
        "        self.assertTrue(np.allclose(bubble_sort_gpu([]), []))\n",
        "\n",
        "    def test_single_element(self):\n",
        "        self.assertTrue(np.allclose(bubble_sort_gpu([42]), [42]))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import numpy as np\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "id": "mOK5VEJkQGH7",
        "outputId": "e8c9e029-ed03-4a0c-edf0-305502f370c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sorting_test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sorting_test.py"
      ],
      "metadata": {
        "id": "H2j97htjRKl9",
        "outputId": "1102e4fe-c391-412a-9bcd-94e72c6d3ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 0.373s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}